{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b9b40",
   "metadata": {},
   "source": [
    "# **More Data** -pt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7c417",
   "metadata": {},
   "source": [
    "Import Modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f7321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497b69f",
   "metadata": {},
   "source": [
    "Login to the tmdb_API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cd395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"moviesDatabase.json\", \"r\") as f:\n",
    "    a = json.load(f)\n",
    "\n",
    "# Set your TMDB API key\n",
    "tmdb.API_KEY = a[\"API-key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe70e9f",
   "metadata": {},
   "source": [
    "- **Define Custom Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e659142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add certification (MPAA Rating) to movie.info\n",
    "def get_movie_with_certification(movie_id):\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    response = movie.info()\n",
    "    certification = movie.release_dates()[\"results\"]\n",
    "    for result in certification:\n",
    "        if result[\"iso_3166_1\"] == \"US\":\n",
    "            movie[\"certification\"] = result[\"release_dates\"][0][\"certification\"]\n",
    "            break\n",
    "    return movie\n",
    "\n",
    "# Function to write data to a JSON file\n",
    "def write_json(new_data, filename):\n",
    "    if not os.path.isfile(filename):\n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump([{\"imdb_id\": 0}], file)\n",
    "\n",
    "    with open(filename, \"r+\") as file:\n",
    "        file_data = json.load(file)\n",
    "        if isinstance(new_data, list) and isinstance(file_data, list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "            file_data.append(new_data)\n",
    "\n",
    "        file.seek(0)\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a4350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function From: https://github.com/coding-dojo-data-science/data-enrichment-helper-functions\n",
    "\n",
    "# Function to read and fix JSON file\n",
    "def read_and_fix_json(JSON_FILE):\n",
    "    try:\n",
    "        with open(JSON_FILE, \"r\") as f:\n",
    "            file_contents = f.read()\n",
    "        print(\"File Contents:\")\n",
    "        print(file_contents)\n",
    "        previous_df = pd.read_json(JSON_FILE)\n",
    "    except ValueError:\n",
    "        with open(JSON_FILE, \"r+\") as f:\n",
    "            data = json.load(f)\n",
    "            if len(data) == 1 and \"imdb_id\" in data[0]:\n",
    "                data.pop(0)\n",
    "                f.seek(0)\n",
    "                json.dump(data, f)\n",
    "                f.truncate()\n",
    "                previous_df = pd.DataFrame(data)\n",
    "            else:\n",
    "                raise Exception(\"Invalid JSON format\")\n",
    "    return previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ce9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if folder Data exists\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89f866",
   "metadata": {},
   "source": [
    "- **Create Outer and Inner Loop:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dbb8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered dataframe from Part 1\n",
    "basics = pd.read_csv(\"Data/title_basics.csv\")\n",
    "\n",
    "# Define the years to extract from the API\n",
    "YEARS_TO_GET = [2000, 2001]\n",
    "\n",
    "# List of errors\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "831af8f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casta\\AppData\\Local\\Temp\\ipykernel_25404\\2575035515.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for YEAR in tqdm_notebook(YEARS_TO_GET, desc=\"YEARS\", position=0):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5693c95b0ce54742aa64045865ec64c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Contents:\n",
      "[{\"imdb_id\": 0}]\n",
      "Previous DataFrame:\n",
      "   imdb_id\n",
      "0        0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casta\\AppData\\Local\\Temp\\ipykernel_25404\\2575035515.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get, desc=f\"Movies from {YEAR}\", position=1, leave=True):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bbb7bdeae3487a8de8d96af3aab765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2000:   0%|          | 0/1450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Contents:\n",
      "[{\"imdb_id\": 0}, \n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 18 (char 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     40\u001b[0m         errors\u001b[38;5;241m.\u001b[39mappend([movie_id, e])\n\u001b[1;32m---> 42\u001b[0m final_year_df \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_fix_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJSON_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m final_year_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mfinal_tmdb_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Year DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [4], line 13\u001b[0m, in \u001b[0;36mread_and_fix_json\u001b[1;34m(JSON_FILE)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(JSON_FILE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 13\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimdb_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     15\u001b[0m             data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dojo-env\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dojo-env\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dojo-env\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dojo-env\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 18 (char 17)"
     ]
    }
   ],
   "source": [
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc=\"YEARS\", position=0):\n",
    "    # Define the JSON file to store results for each year\n",
    "    JSON_FILE = f\"{FOLDER}tmdb_api_results_{YEAR}.json\"\n",
    "\n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "    # If it does not exist, save an empty dict with just imdb_id to the new json file.\n",
    "    if not file_exists:\n",
    "        with open(JSON_FILE, \"w\") as f:\n",
    "            json.dump({\"imdb_id\": 0}, f)\n",
    "    \n",
    "    # Saving new year as the current dataframe\n",
    "    df = basics.loc[basics[\"startYear\"] == YEAR].copy()\n",
    "    \n",
    "    # Saving movie ids to a list\n",
    "    movie_ids = df[\"tconst\"].copy()\n",
    "\n",
    "    # Load existing data from JSON into a dataframe called \"previous_df\"\n",
    "    previous_df = read_and_fix_json(JSON_FILE)\n",
    "    print(\"Previous DataFrame:\")\n",
    "    print(previous_df)\n",
    "\n",
    "    # Filter out any ids that are already in the JSON_FILE\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df[\"imdb_id\"])]\n",
    "\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get, desc=f\"Movies from {YEAR}\", position=1, leave=True):\n",
    "        try:\n",
    "            # Retrieve the data for the movie id and add certification\n",
    "            temp = get_movie_with_certification(movie_id)\n",
    "            \n",
    "            # Append/extend results to the existing file using the write_json function\n",
    "            write_json(temp, JSON_FILE)\n",
    "            \n",
    "            # Short sleep to prevent overwhelming the server\n",
    "            time.sleep(0.02)\n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "    \n",
    "    final_year_df = read_and_fix_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "    \n",
    "    print(\"Final Year DataFrame:\")\n",
    "    print(final_year_df)\n",
    "\n",
    "print(f\"- Total errors: {len(errors)}\")\n",
    "print(\"Inner Loop Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
